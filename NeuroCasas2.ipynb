{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": " NeuroCasas2.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "EIdT9iu_Z4Rb"
      },
      "source": [
        "# Regresion usando redes neuronales"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "moB4tpEHxKB3",
        "colab": {}
      },
      "source": [
        "# Use seaborn for pairplot\n",
        "!pip install seaborn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1rRo8oNqZ-Rj",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "import pathlib\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "syBOftoYZJZj",
        "colab_type": "text"
      },
      "source": [
        "Obtenga la data.\n",
        "\n",
        "Primero se obtiene el dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xMFHlPuy3-Dq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive2', force_remount=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBDuQ3V-3rLl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset=pd.read_csv(\"/content/drive2/My Drive/Colab Notebooks/preprocesamiento/train_v5_sal.csv\")\n",
        "dataset.pop('Unnamed: 0')\n",
        "dataset = dataset.iloc[:, 0:60]\n",
        "dataset.head()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nslsRLh7Zss4"
      },
      "source": [
        "Importelo usando pandas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3MWuJTKEDM-f"
      },
      "source": [
        "### Limpie la data\n",
        "\n",
        "El set de datos contiene algunos valores desconocidos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JEJHhN65a2VV",
        "colab": {}
      },
      "source": [
        "dataset.isna().sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9UPN0KBHa_WI"
      },
      "source": [
        "En caso de encontrar datos faltantes, se sustituyen por 0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4ZUDosChC1UN",
        "colab": {}
      },
      "source": [
        "dataset = dataset.fillna(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Cuym4yvk76vU"
      },
      "source": [
        "### Dividamos la data en entrenamiento y validación\n",
        "\n",
        "Se divide el  set de datos en un set de entrenamiento y otro para validar.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qn-IGhUE7_1H",
        "colab": {}
      },
      "source": [
        "train_dataset = dataset.sample(frac=0.8,random_state=0)\n",
        "val_dataset = dataset.drop(train_dataset.index)\n",
        "print(train_dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "J4ubs136WLNp"
      },
      "source": [
        "### Inspeccione la data\n",
        "\n",
        "Revise rapidamente la distribucion conjunta de un par de columnas de el set de entrenamiento."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oRKO_x8gWKv-",
        "colab": {}
      },
      "source": [
        "sns.pairplot(train_dataset[[\"SalePrice\", \"LotArea\", \"OverallQual\", \"YearBuilt\"]], diag_kind=\"kde\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gavKO_6DWRMP"
      },
      "source": [
        "Tambien revise las estadisticas generales:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yi2FzC3T21jR",
        "colab": {}
      },
      "source": [
        "train_stats = train_dataset.describe()\n",
        "train_stats.pop(\"SalePrice\")\n",
        "train_stats = train_stats.transpose()\n",
        "train_stats"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Db7Auq1yXUvh"
      },
      "source": [
        "### Separe las caracteristicas de las etiquetas.\n",
        "\n",
        "Separe el valor objetivo, o la \"etiqueta\" \n",
        "de las caracteristicas. Esta etiqueta es el valor que entrenara el modelo para predecir."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "t2sluJdCW7jN",
        "colab": {}
      },
      "source": [
        "train_labels = train_dataset.pop('SalePrice')\n",
        "val_labels = val_dataset.pop('SalePrice')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mRklxK5s388r"
      },
      "source": [
        "### Normalice la data\n",
        "\n",
        "Revise otra vez el bloque de `train_stats` que se presento antes y note la diferencia de rangos de cada caracteristica."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-ywmerQ6dSox"
      },
      "source": [
        "Es una buena práctica normalizar funciones que utilizan diferentes escalas y rangos. Aunque el modelo * podría * converger sin normalización de características, dificulta el entrenamiento y hace que el modelo resultante dependa de la elección de las unidades utilizadas en la entrada.\n",
        "\n",
        "Nota: Aunque generamos intencionalmente estas estadísticas solo del conjunto de datos de entrenamiento, estas estadísticas también se utilizarán para normalizar el conjunto de datos de prueba. Necesitamos hacer eso para proyectar el conjunto de datos de prueba en la misma distribución en la que el modelo ha sido entrenado."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JlC5ooJrgjQF",
        "colab": {}
      },
      "source": [
        "def norm(x):\n",
        "  return (x - train_stats['mean']) / train_stats['std']\n",
        "normed_train_data = norm(train_dataset)\n",
        "normed_val_data = norm(val_dataset)\n",
        "normed_train_data.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "BuiClDk45eS4"
      },
      "source": [
        "Estos datos normalizados es lo que usaremos para entrenar el modelo.\n",
        "\n",
        "Precaución: las estadísticas utilizadas para normalizar las entradas aquí (media y desviación estándar) deben aplicarse a cualquier otro dato que se alimente al modelo, junto con la codificación de un punto que hicimos anteriormente. Eso incluye el conjunto de pruebas, así como los datos en vivo cuando el modelo se usa en producción."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SmjdzxKzEu1-"
      },
      "source": [
        "## El modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6SWtkIjhrZwa"
      },
      "source": [
        "### Construye el modelo\n",
        "\n",
        "Construyamos nuestro modelo. Aquí, utilizaremos un modelo `secuencial` con dos capas ocultas densamente conectadas y una capa de salida que devuelve un único valor continuo. Los pasos de construcción del modelo se envuelven en una función, `build_model`, ya que crearemos un segundo modelo, más adelante."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "c26juK7ZG8j-",
        "colab": {}
      },
      "source": [
        "def build_model():\n",
        "  model = keras.Sequential([\n",
        "    layers.Dense(100, activation='relu', input_shape=[len(train_dataset.keys())]),\n",
        "    layers.Dense(50, activation='relu'),\n",
        "    layers.Dense(1, activation='relu')\n",
        "  ])\n",
        "\n",
        "  optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
        "\n",
        "  model.compile(loss='mse',\n",
        "                optimizer=optimizer,\n",
        "                metrics=['mae', 'mse', tf.keras.metrics.RootMeanSquaredError(name='rmse')])\n",
        "  return model\n",
        "\n",
        "model = build_model()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Sj49Og4YGULr"
      },
      "source": [
        "### Inspeccione el modelo\n",
        "\n",
        "Use el método `.summary` para imprimir una descripción simple del modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ReAD0n6MsFK-",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Vt6W50qGsJAL"
      },
      "source": [
        "\n",
        "Ahora pruebe el modelo. Tome un lote de ejemplos `10` de los datos de entrenamiento y llame a` model.predict` en él."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-d-gBaVtGTSC",
        "colab": {}
      },
      "source": [
        "example_batch = normed_train_data[:10]\n",
        "example_result = model.predict(example_batch)\n",
        "example_result\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QlM8KrSOsaYo"
      },
      "source": [
        "Parece estar funcionando, y produce un resultado de la forma y tipo esperados."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0-qWCsh6DlyH"
      },
      "source": [
        "### Entrenar a la modelo\n",
        "\n",
        "Entrene el modelo durante 1000 épocas y registre la precisión de entrenamiento y validación en el objeto `history`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sD7qHCmNIOY0",
        "colab": {}
      },
      "source": [
        "# Display training progress by printing a single dot for each completed epoch\n",
        "class PrintDot(keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs):\n",
        "    if epoch % 100 == 0: print('')\n",
        "    print('.', end='')\n",
        "\n",
        "EPOCHS = 2000\n",
        "\n",
        "history = model.fit(\n",
        "  normed_train_data, train_labels,\n",
        "  epochs=EPOCHS, validation_split = 0.2, verbose=0,\n",
        "  callbacks=[PrintDot()])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tQm3pc0FYPQB"
      },
      "source": [
        "Visualice el progreso de entrenamiento del modelo usando las estadísticas almacenadas en el objeto `history`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4Xj91b-dymEy",
        "colab": {}
      },
      "source": [
        "hist = pd.DataFrame(history.history)\n",
        "hist['epoch'] = history.epoch\n",
        "hist.tail()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "B6XriGbVPh2t",
        "colab": {}
      },
      "source": [
        "def plot_history(history):\n",
        "  hist = pd.DataFrame(history.history)\n",
        "  hist['epoch'] = history.epoch\n",
        "\n",
        "  plt.figure()\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Mean Abs Error [$]')\n",
        "  plt.plot(hist['epoch'], hist['mae'],\n",
        "           label='Train Error')\n",
        "  plt.plot(hist['epoch'], hist['val_mae'],\n",
        "           label = 'Val Error')\n",
        "  plt.ylim([0,100000])\n",
        "  plt.legend()\n",
        "\n",
        "  plt.figure()\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Mean Square Error [$MPG^2$]')\n",
        "  plt.plot(hist['epoch'], hist['mse'],\n",
        "           label='Train Error')\n",
        "  plt.plot(hist['epoch'], hist['val_mse'],\n",
        "           label = 'Val Error')\n",
        "  plt.ylim([0,10000000000])\n",
        "  plt.legend()\n",
        "\n",
        "  plt.figure()\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Mean Square Error [$MPG^2$]')\n",
        "  plt.plot(hist['epoch'], hist['rmse'],\n",
        "           label='Train Error')\n",
        "  plt.plot(hist['epoch'], hist['val_rmse'],\n",
        "           label = 'Val Error')\n",
        "  plt.ylim([0,100000])\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "plot_history(history)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "AqsuANc11FYv"
      },
      "source": [
        "Este gráfico muestra poca mejora, o incluso degradación en el error de validación después de aproximadamente 100 épocas. Actualicemos la llamada `model.fit` para detener automáticamente el entrenamiento cuando el puntaje de validación no mejore. Utilizaremos una * devolución de llamada de EarlyStopping * que pruebe una condición de entrenamiento para cada época. Si transcurre una cantidad determinada de épocas sin mostrar mejoría, entonces detiene automáticamente el entrenamiento.\n",
        "\n",
        "Puedes obtener más información sobre esta devolución de llamada [Aca](https://www.tensorflow.org/versions/master/api_docs/python/tf/keras/callbacks/EarlyStopping)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fdMZuhUgzMZ4",
        "colab": {}
      },
      "source": [
        "model = build_model()\n",
        "\n",
        "# The patience parameter is the amount of epochs to check for improvement\n",
        "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=50)\n",
        "\n",
        "history = model.fit(normed_train_data, train_labels, epochs=EPOCHS,\n",
        "                    validation_split = 0.2, verbose=0, callbacks=[early_stop, PrintDot()])\n",
        "\n",
        "plot_history(history)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3St8-DmrX8P4"
      },
      "source": [
        "Veamos qué tan bien generaliza el modelo al usar el conjunto ** test **, que no usamos al entrenar el modelo. Esto nos dice qué tan bien podemos esperar que el modelo prediga cuándo lo usamos en el mundo real."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jl_yNr5n1kms",
        "colab": {}
      },
      "source": [
        "loss, mae, mse = model.evaluate(normed_val_data, val_labels, verbose=2)\n",
        "\n",
        "print(\"Testing set Mean Abs Error: {:5.2f} MPG\".format(mae))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ft603OzXuEZC"
      },
      "source": [
        "### Haga Predicciones\n",
        "\n",
        "Finalmente, prediga los valores de MPG utilizando datos en el conjunto de pruebas:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Xe7RXH3N3CWU",
        "colab": {}
      },
      "source": [
        "val_predictions = model.predict(normed_val_data).flatten()\n",
        "\n",
        "plt.scatter(val_labels, val_predictions)\n",
        "plt.xlabel('True Values [MPG]')\n",
        "plt.ylabel('Predictions [MPG]')\n",
        "plt.axis('equal')\n",
        "plt.axis('square')\n",
        "plt.xlim([0,plt.xlim()[1]])\n",
        "plt.ylim([0,plt.ylim()[1]])\n",
        "_ = plt.plot([0, 600000], [0, 600000])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "19wyogbOSU5t"
      },
      "source": [
        "Parece que nuestro modelo predice razonablemente bien. Echemos un vistazo a la distribución de errores."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "f-OHX4DiXd8x",
        "colab": {}
      },
      "source": [
        "error = val_predictions - val_labels\n",
        "plt.hist(error, bins = 25)\n",
        "plt.xlabel(\"Prediction Error [MPG]\")\n",
        "_ = plt.ylabel(\"Count\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "m0CB5tBjSU5w"
      },
      "source": [
        "No es del todo gaussiano, pero podríamos esperar eso porque el número de muestras es muy pequeño."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JeRsLC_sDNuT",
        "colab_type": "text"
      },
      "source": [
        "## Reentrenamiento con todos los datos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zj20q8NhEKIr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "todo_labels = dataset.pop('SalePrice')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pazk6_loEvax",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "normed_data = norm(dataset)\n",
        "normed_data.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mID5K87ODZjT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = build_model()\n",
        "\n",
        "#early_stop = keras.callbacks.EarlyStopping(monitor='loss', patience=50)\n",
        "\n",
        "history = model.fit(normed_data, todo_labels, epochs=870,\n",
        "                    validation_split = 0, verbose=0, callbacks=[early_stop, PrintDot()])\n",
        "\n",
        "#plot_history(history)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vgGQuV-yqYZH"
      },
      "source": [
        "## Generar archivo para Kaggle\n",
        "\n",
        "\n",
        "* "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8NdvawVYibLi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset2=pd.read_csv(\"/content/drive2/My Drive/Colab Notebooks/preprocesamiento/test_v5_sal.csv\")\n",
        "dataset2.pop('Unnamed: 0')\n",
        "dataset2 = dataset2.iloc[:, 0:59]\n",
        "dataset2.head()\n",
        "print(dataset2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5nxf2agfiu8z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset2.isna().sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kcvJQp-Hi6Eg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset2 = dataset2.fillna(0)\n",
        "dataset2.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pqdwJov6jLTZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "normed_test2_data = norm(dataset2)\n",
        "normed_test2_data.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EAyWzzBTkRtv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ynew = model.predict(normed_test2_data)\n",
        "print(ynew)\n",
        "dfsal = pd.DataFrame(ynew)\n",
        "dfsal.columns = ['SalePrice']\n",
        "print (dfsal)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFCCbLqFurIe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "my_list = list(range(1461,2920))\n",
        "print(my_list)\n",
        "dfid = pd.DataFrame(my_list)\n",
        "dfid.columns = ['Id'] \n",
        "print (dfid)\n",
        "resultados = pd.concat([\n",
        "    dfid,dfsal\n",
        "], axis=1)\n",
        "#resultados.ignore_index()\n",
        "print(resultados)\n",
        "resultados.to_csv(\"/content/drive2/My Drive/Colab Notebooks/preprocesamiento/resultados_v12_sal.csv\", index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}